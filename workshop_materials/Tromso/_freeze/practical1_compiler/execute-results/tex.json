{
  "hash": "3b71004a431404bb40bc841554313566",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Practical\"\nformat: \n  html:\n    number-sections: true\n    mainfont: Times New Roman\n  PrettyPDF-pdf:\n    keep-tex:  true\n    number-sections: true\nembed-resources: true\nexecute: \n  freeze: auto\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell}\n\n:::\n\n\n<font size=\"5\"> **Aim of this practical:** </font>\n\nIn this first practical we are going to learn how fit a point process model to transect data using `inlabru`\n\n{{< downloadthis practical1_compiler.R dname=\"session_1\" label = \"Download Practical 1 R script\" icon=\"database-fill-down\" type=\"success\" >}}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n# Distance Sampling\n\nIn this practical we will:\n\n-   Fit a spatial distance sampling model\n-   Estimate animal abundance\n-   Compare models that use different detection functions\n\nLibraries to load:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(INLA)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(inlabru)     \nlibrary(sf)\n# load some libraries to generate nice map plots\nlibrary(scico)\nlibrary(mapview)\n```\n:::\n\n\n## The data\n\nIn the next exercise, we will explore data from a combination of several NOAA shipboard surveys conducted on pan-tropical spotted dolphins in the Gulf of Mexico. The data set is available in `inlabru` (originally obtained from the `dsm` R package) and contains the following information:\n\n-   A total of 47 observations of groups of dolphins were detected. The group size was recorded, as well as the Beaufort sea state at the time of the observation.\n\n-   Transect width is 16 km, i.e. maximal detection distance 8 km (transect half-width 8 km).\n\nWe can load and visualize the data as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmexdolphin <- mexdolphin_sf\nmexdolphin$depth <- mexdolphin$depth %>% mutate(depth=scale(depth)%>%c())\nmapviewOptions(basemaps = c( \"OpenStreetMap.DE\"))\n\nmapview(mexdolphin$points,zcol=\"size\")+\n  mapview(mexdolphin$samplers)+\n mapview(mexdolphin$ppoly )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nfile:////private/var/folders/66/sbcktl916ln9wbwvt5hnfw0h0000gn/T/RtmpZ5fN6j/file15797292b085f/widget157974832aa16.html screenshot completed\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## The workflow\n\nTo model the density of spotted dolphins we take a thinned point process model of the form:\n\n$$\np(\\mathbf{y} | \\lambda)  \\propto \\exp \\left( -\\int_\\Omega \\lambda(\\mathbf{s}) p(\\mathbf{s}) \\mathrm{d}\\mathbf{s} \\right) \\prod_{i=1}^n \\lambda(\\mathbf{s}_i) p(\\mathbf{s}_i)) \n$$ {#eq-thinned_pp}\n\nWhen fitting a distance sampling model we need to fulfill the following tasks:\n\n1.  Build the mesh\n\n2.  Define the SPDE representation of the spatial GF. This includes defining the priors for the range and sd of the spatial GF\n\n3.  Define the *components* of the linear predictor. This includes the spatial GF and all eventual covariates\n\n4.  Define the observation model using the `bru_obs()` function\n\n5.  Run the model using the `bru()` function\n\n### Building the mesh\n\nThe first task is to build the mesh that covers the area of interest. For this purpose we use the function `fm_mesh_2d`. To do so, we need to define the area of interest. We can either use a predefined boundary or create a non convex hull surrounding the location of the specie sightseeings\n\n::: panel-tabset\n## non-covex hull\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboundary0 = fm_nonconvex_hull(mexdolphin$points,convex = -0.1)\n\nmesh_0 = fm_mesh_2d(boundary = boundary0,\n                          max.edge = c(30, 150), # The largest allowed triangle edge length.\n                          cutoff = 15,\n                          crs = fm_crs(mexdolphin$points))\nggplot() + gg(mesh_0)\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## domain boundary\n\nThe `mexdolphin` object contains a predefined region of interest which can be accessed through `mexdolphin$ppoly`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmesh_1 = fm_mesh_2d(boundary = mexdolphin$ppoly,\n                    max.edge = c(30, 150),\n                    cutoff = 15,\n                    crs = fm_crs(mexdolphin$points))\nggplot() + gg(mesh_1)\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n:::\n\nKey parameters in mesh construction include: `max.edge` for maximum triangle edge lengths, `offset` for inner and outer extensions (to prevent edge effects), and cutoff to avoid overly small triangles in clustered areas.\n\n::: callout-note\n**General guidelines for creating the mesh**\n\n1.  Create triangulation meshes with `fm_mesh_2d()`\n2.  Move undesired boundary effects away from the domain of interest by extending to a smooth external boundary\n3.  Use a coarser resolution in the extension to reduce computational cost (`max.edge=c(inner, outer)`)\n4.  Use a fine resolution (subject to available computational resources) for the domain of interest (inner correlation range) and filter out small input point clusters (0 \\< `cutoff` \\< inner)\n5.  Coastlines and similar can be added to the domain specification in `fm_mesh_2d()` through the `boundary` argument.\n:::\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task\n\nLook at the documentation for the `fm_mesh_2d` function typing\n\n\n::: {.cell}\n\n```{.r .cell-code}\n?fm_mesh_2d\n```\n:::\n\n\nplay around with the different options and create different meshes. You can compare these against a pre-computed mesh available by typing `plot(mexdolphin$mesh)`\n\nThe *rule of thumb* is that your mesh should be:\n\n-   fine enough to well represent the spatial variability of your process, but not too fine in order to avoid computation burden\n-   the triangles should be regular, avoid long and thin triangles.\n-   The mesh should contain a buffer around your area of interest (this is what is defined in the `offset` option) in order to avoid boundary artefact in the estimated variance.\n:::\n\n**Projecting the covariate**\n\nFor point process models the spatial covariate has to cover the whole domain including the out mesh. To achieve this we can:\n\n1.  Convert the `sf` spatial object containing the covariate values (i.e., depth) to a raster object using the `st_rasterize` function form `stars` which can then be transformed into a `terra` raster as follows:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(terra)\n    library(stars)\n    # Convert sf to stars raster\n    stars_raster <- st_rasterize(mexdolphin$depth[, \"depth\"])\n    # Convert stars to terra raster if needed\n    terra_raster <- rast(stars_raster)\n    ```\n    :::\n\n\n2.  Then, we can extend the raster resolution and use the `bru_fill_missing` function to fill-in the missing values with the nearest available value using the following code:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Extend raster ext by 5 % of the original raster\n    re <- extend(terra_raster, ext(terra_raster)*2.1)\n    # Convert to an sf spatial object\n    re_df <- re %>% stars::st_as_stars() %>%  st_as_sf(na.rm=F)\n    # fill in missing values using the original raster \n    re_df$depth <- bru_fill_missing(terra_raster,re_df,re_df$depth)\n    # store the projectes values as a raster\n    depth_rast_p <- stars::st_rasterize(re_df) %>% rast()\n    ```\n    :::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-10-1.pdf){fig-align='center'}\n:::\n:::\n\n\n### Define the SPDE representation of the spatial GF\n\nTo define the SPDE representation of the spatial GF we use the function `inla.spde2.pcmatern`. This takes as input the mesh we have defined and the PC-priors definition for $\\rho$ and $\\sigma$ (the range and the marginal standard deviation of the field).\n\nPC priors Gaussian Random field are defined in (Fuglstad et al. 2018). From a practical perspective for the range $\\rho$ you need to define two paramters $\\rho_0$ and $p_{\\rho}$ such that you believe it is reasonable that\n\n$$\nP(\\rho<\\rho_0)=p_{\\rho}\n$$\n\nwhile for the marginal variance $\\sigma$ you need to define two parameters $\\sigma_0$ and $p_{\\sigma}$ such that you believe it is reasonable that\n\n$$\nP(\\sigma>\\sigma_0)=p_{\\sigma}\n$$\n\n::: {.callout-tip icon=\"false\"}\n## {{< bi question-octagon color=#6dc83c >}} Question\n\nTake a look at the code below and select which of the following statements about the specified Matérn PC priors are true.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspde_model <- inla.spde2.pcmatern(mexdolphin$mesh,\n  prior.sigma = c(2, 0.01),\n  prior.range = c(50, 0.01)\n)\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n* (A) there is probability of 0.01 that the spatial range is greater or equal than 50  \n* (B) the probability that the spatial range is smaller than 50 is very small  \n* (C) the probability that the marginal standard deviation is smaller than 2 is very small  \n* (D) there is probability of 0.99 that the marginal standard deviation is less or equal than 2  \n\n\n:::\n\n### Define the components of the linear predictor\n\nWe have now defined a mesh and a SPDE representation of the spatial GF. We now need to define the model components.\n\nFirst, we need to define the detection function. Here, we will define a half-normal detection probability function. This must take distance as its first argument and the linear predictor of the sigma parameter as its second:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhn <- function(distance, sigma) {\n  exp(-0.5 * (distance / sigma)^2)\n}\n```\n:::\n\n\nWe need to now separately define the components of the model including the SPDE model, the Intercept, the effect of depth and the detection function parameter `sigma`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncmp <- ~ space(main = geometry, model = spde_model) +\n  sigma(1,\n    prec.linear = 1,\n    marginal = bm_marginal(qexp, pexp, dexp, rate = 1 / 8)\n  ) +\n  depth(depth_rast_p$depth,model=\"linear\")+\n  Intercept(1)\n```\n:::\n\n\n::: callout-note\nTo control the prior distribution for the `sigma` parameter, we use a transformation mapper that converts a latent variable into an exponentially distributed variable with expectation 8 (this is a somewhat arbitrary value, but motivated by the maximum observation distance W)\n\nThe `marginal` argument in the `sigma` component specifies the transformation function taking N(0,1) to Exponential(1/8).\n:::\n\nThe formula, which describes how these components are combined to form the linear predictor\n\n$$\\log \\color{red}{\\tilde{\\lambda}(s)} = \\overbrace{\\log \\lambda (s)}^{\\beta_0 + \\beta_1 x(s) + \\xi(s)} + \\overbrace{\\log \\color{red}{g(d(s))}}^{-0.5~d(\\mathbf{s})^2\\sigma^{-2}}$$\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task\n\nComplete the code below to define the formula\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta <- ... + log(2)  \n```\n:::\n\n\n\n::: {.cell layout-align=\"center\" webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code}\neta <- geometry + distance ~ space +  \n  log(hn(distance, sigma)) +\n  depth +\n  Intercept + log(2)  \n```\n\n\n</div>\n:::\n\n:::\n\nHere, the `log(2)` offset in the predictor takes care of the two-sided detections\n\n### Define the observation model\n\n`inlabru` has support for latent Gaussian Cox processes through the `cp` likelihood family. To fit a point process model recall that we need to approximate the integral in using a numerical integration scheme as:\n\n$$\n\\approx\\exp\\left(-\\sum_{k=1}^{N_k}w_k\\lambda(s_k)\\right)\\prod_{i=1}^n \\lambda(\\mathbf{s}_i)\n$$\n\nThus, we first create our integration scheme using the `fm_int` function by specifying integration domains for the spatial and distance dimensions.\n\nHere we use the same points to define the SPDE approximation and to approximate the integral in @eq-thinned_pp, so that the integration weight and SPDE weights are consistent with each other. We also need to explicitly integrate over the distance dimension so we use the `fm_mesh_1d()` to create mesh over the samplers (which are the transect lines in this dataset, so we need to tell `inlabru` about the strip half-width).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# build integration scheme\ndistance_domain <-  fm_mesh_1d(seq(0, 8,\n                              length.out = 30))\nips = fm_int(list(geometry = mexdolphin$mesh,\n                  distance = distance_domain),\n             samplers = mexdolphin$samplers)\n```\n:::\n\n\nNow, we just need to supply the `sf` object as our data and the integration scheme `ips`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlik = bru_obs(\"cp\",\n              formula = eta,\n              data = mexdolphin$points,\n              ips = ips)\n```\n:::\n\n\nThen we fit the model, passing both the components and the observational model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit = bru(cmp, lik)\n```\n:::\n\n\n::: callout-note\n`inlabru` supports a shortcut for defining the integration points using the `domain` and `samplers` argument of `bru_obs()`. This `domain` argument expects a list of named domains with inputs that are then internally passed to `fm_int()` to build the integration scheme. The `samplers` argument is used to define subsets of the domain over which the integral should be computed. An equivalent way to define the same model as above is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlik = bru_obs(formula = eta, \n              data = mexdolphin$points, \n              family = \"cp\",\n              domain = list(\n                geometry = mesh,\n                distance = fm_mesh_1d(seq(0, 8, length.out = 30))),\n              samplers = mexdolphin$samplers)\n```\n:::\n\n:::\n\n## Visualize model Results\n\n### Posterior summaries\n\nWe can use the `fit$summary.fixed` and `summary.hyperpar` to obtain posterior summaries of the model parameters.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}\n\\fontsize{12.0pt}{14.0pt}\\selectfont\n\\begin{tabular*}{\\linewidth}{@{\\extracolsep{\\fill}}l|rrr}\n\\toprule\n & mean & 0.025quant & 0.975quant \\\\ \n\\midrule\\addlinespace[2.5pt]\nsigma & -0.05 & -0.46 & 0.36 \\\\ \ndepth & 0.57 & 0.14 & 1.05 \\\\ \nIntercept & -8.09 & -9.28 & -7.14 \\\\ \nRange for space & 344.79 & 122.58 & 813.71 \\\\ \nStdev for space & 0.85 & 0.42 & 1.49 \\\\ \n\\bottomrule\n\\end{tabular*}\n\\end{table}\n\n:::\n:::\n\n\nLook at the SPDE parameter posteriors as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot( spde.posterior(fit, \"space\", what = \"range\")) +\nplot( spde.posterior(fit, \"space\", what = \"log.variance\"))  \n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-22-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n### Model predictions\n\nWe now want to extract the estimated posterior mean and sd of spatial GF. To do this we first need to define a grid of points where we want to predict. We do this using the function `fm_pixel()` which creates a regular grid of points covering the mesh\n\n\n::: {.cell}\n\n```{.r .cell-code}\npxl <- fm_pixels(mexdolphin$mesh, dims = c(200, 100), mask = mexdolphin$ppoly)\n```\n:::\n\n\nthen compute the prediction for both the spatial GF and the linear predictor (spatial GF + intercept + depth covariate)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npr.int = predict(fit, pxl, ~data.frame(spatial = space,\n                                      lambda = exp(Intercept + depth + space)))\n```\n:::\n\n\nFinally, we can plot the maps of the spatial effect\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() + geom_sf(data = pr.int$spatial,aes(color = mean)) + scale_color_scico() + ggtitle(\"Posterior mean\")\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-25-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nggplot() + geom_sf(data = pr.int$spatial,aes(color = sd)) + scale_color_scico() + ggtitle(\"Posterior sd\")\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-25-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n**Note** The posterior sd is lowest at the observation points. Note how the posterior sd is inflated around the border, this is the \"border effect\" due to the SPDE representation.\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task\n\nUsing the predictions stored in `pr.int`, produce a map of the posterior mean intensity.\n\n\n<div class='webex-solution'><button>Take hint</button>\n\n\nRecall that the predicted intensity is given by $\\lambda(s) = \\exp\\{\\beta_0+ \\beta_1~ \\text{depth}(s)+\\xi(s)\\}$\n\n\n</div>\n\n\n\n::: {.cell layout-align=\"center\" webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nggplot() + \n  geom_sf(data = pr.int$lambda,aes(color = mean)) +\n  scale_color_scico(palette = \"imola\") +\n  ggtitle(\"Posterior mean\")\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-26-1.pdf){fig-align='center' fig-pos='H'}\n:::\n\n\n</div>\n:::\n\n:::\n\nWe can predict the detection function in a similar fashion. Here, we should make sure that it doesn’t try to evaluate the effects of components that can’t be evaluated using the given input data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistdf <- data.frame(distance = seq(0, 8, length.out = 100))\ndfun <- predict(fit, distdf, ~ hn(distance, sigma))\nplot(dfun)\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-27-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Abundance estimates\n\nThe mean expected number of animals can be computed by integrating the intensity over the region of interest as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredpts <- fm_int(mexdolphin$mesh, mexdolphin$ppoly)\nLambda <- predict(fit, predpts, ~ sum(weight * exp(space + Intercept)))\nLambda\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      mean       sd   q0.025     q0.5   q0.975   median sd.mc_std_err\n1 256.5226 54.74652 178.1482 251.2055 381.2504 251.2055      4.387893\n  mean.mc_std_err\n1        6.352231\n```\n\n\n:::\n:::\n\n\nTo fully propagate the uncertainty on the expected number animals we can draw Monte Carlo samples from the fitted model as follows (this could take a couple of minutes):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNs <- seq(50, 450, by = 1)\nNest <- predict(fit, predpts,\n  ~ data.frame(\n    N = Ns,\n    density = dpois(\n      Ns,\n      lambda = sum(weight * exp(space + Intercept))\n    )\n  ),\n  n.samples = 2000\n)\n```\n:::\n\n\nWe can compare this with a simpler \"plug-in\" approximation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNest <- dplyr::bind_rows(\n  cbind(Nest, Method = \"Posterior\"),\n  data.frame(\n    N = Nest$N,\n    mean = dpois(Nest$N, lambda = Lambda$mean),\n    mean.mc_std_err = 0,\n    Method = \"Plugin\"\n  )\n)\n```\n:::\n\n\nThen, we can visualize the result as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = Nest) +\n  geom_line(aes(x = N, y = mean, colour = Method)) +\n  geom_ribbon(\n    aes(\n      x = N,\n      ymin = mean - 2 * mean.mc_std_err,\n      ymax = mean + 2 * mean.mc_std_err,\n      fill = Method,\n    ),\n    alpha = 0.2\n  ) +\n  geom_line(aes(x = N, y = mean, colour = Method)) +\n  ylab(\"Probability mass function\")\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-31-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## Model checks\n\nLastly, we can assess the goodness-of-fit of the models by comparing the observed counts across different distance bins and the expected counts and their associated uncertainty:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbc <- bincount(\n  result = fit,\n  observations = mexdolphin$points$distance,\n  breaks = seq(0, max(mexdolphin$points$distance), length.out = 9),\n  predictor = distance ~ hn(distance, sigma)\n)\nattributes(bc)$ggp\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-32-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task\n\nFit a model using a hazard detection function instead and compare the GoF of this model with that from the half-normal detection model. Recall that the hazard detection function is given by:\n\n$$\ng(\\mathbf{s}|\\sigma) = 1 - \\exp(-(d(\\mathbf{s})/\\sigma)^{-1})\n$$\n\n\n<div class='webex-solution'><button>Take hint</button>\n\n\nThe hazard function can be codes as:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhr <- function(distance, sigma) {\n  1 - exp(-(distance / sigma)^-1)\n}\n```\n:::\n\n\nYou can use the same prior for the `sigma` parameter as for the half-Normal model (such parameters aren’t always comparable, but in this example it’s a reasonable choice). You can also use the `lgcp` function as a shortcut to fit the model (type `?lgcp` for further details).\n\n\n</div>\n\n\n\n::: {.cell layout-align=\"center\" webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nformula1 <- geometry + distance ~ space +\n  log(hr(distance, sigma)) +\n  Intercept + log(2)\n\n# here we use the shorcut to specify the model\nfit1 <- lgcp(\n  components = cmp,\n  mexdolphin$points,\n  samplers = mexdolphin$samplers,\n  domain = list(\n    geometry = mexdolphin$mesh,\n    distance = fm_mesh_1d(seq(0, 8, length.out = 30))\n  ),\n  formula = formula1\n)\n\nbc1 <- bincount(\n  result = fit1,\n  observations = mexdolphin$points$distance,\n  breaks = seq(0, max(mexdolphin$points$distance), length.out = 9),\n  predictor = distance ~ hn(distance, sigma)\n)\nattributes(bc1)$ggp\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-34-1.pdf){fig-align='center' fig-pos='H'}\n:::\n\n\n</div>\n:::\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n# Space-time model for transect survey data\n\nIn this practical we will:\n\n-   Fit a spatio-temporal model to transect survey data.\n\nLibraries to load:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(INLA)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(inlabru)     \nlibrary(sf)\n# load some libraries to generate nice map plots\nlibrary(scico)\nlibrary(mapview)\n```\n:::\n\n\n## The data\n\nIn the next exercise, we will work with simulate spatiotemporal transect survey data from the `MRSea` package which is available on `inlabru`.\n\nWe can load and visualize the data as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmrsea <- inlabru::mrsea\n\nggplot() +\n  geom_fm(data = mrsea$mesh) +\n  gg(mrsea$boundary) +\n  gg(mrsea$samplers) +\n  gg(mrsea$points, size = 0.5) +\n  facet_wrap(~season) +\n  ggtitle(\"MRSea observation seasons\")\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-72-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n## The workflow\n\n### The Model\n\nFor computational purposes we will assume perfect detection along the transects and thus, the spatiotemporal animal density is modelled using a point process model of the form:\n\n$$\np(\\mathbf{y} | \\lambda)  \\propto \\exp \\left( -\\int_\\Omega \\lambda(\\mathbf{s,t}) \\mathrm{d}\\mathbf{s,t} \\right) \\prod_{i=1}^n \\lambda(\\mathbf{s}_i,t)) \n$$\n\n### The SPDE model\n\nFirst, we define the SPDE model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatern <- inla.spde2.pcmatern(mrsea$mesh,\n  prior.sigma = c(0.1, 0.01),\n  prior.range = c(10, 0.01)\n)\n```\n:::\n\n\n### Model components\n\nIn this example we will employ a spatio-temporal SPDE component. Note how the `group` and `ngroup` parameters are employed to let the SPDE model know about the name of the time dimension (season) and the total number of distinct points in time. Further control of the spatio-temporal filed can be passed as a list through the the `control.group` argument. In this case, we specify an `iid` effect to describe how the spatial field evolves in time (this could be change to accommodate a time dependent structure such as an AR(1) model).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncmp <- ~ Intercept(1) + \n  space_time(\n    geometry,\n    model = matern,\n    group = season,\n    ngroup = 4,\n    control.group = list(model=\"iid\")\n  )\n```\n:::\n\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task\n\nComplete the following code to define the linear predictor:\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta <- ... + ... ~ ... + ...\n```\n:::\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\neta <- geometry + season ~ space_time +\n  Intercept \n```\n\n\n</div>\n:::\n\n:::\n\n### Build the observational model\n\nWe can now build the integration scheme using the `fm_int()` function by specifying the domain and samplers arguments. Note that omitting the season dimension from domain would lead to aggregation of all sampling regions over time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nips <- fm_int(\n  domain = list(geometry = mrsea$mesh, season = 1:4),\n  samplers = mrsea$samplers\n)\n```\n:::\n\n\n::: {.callout-warning icon=\"false\"}\n## {{< bi pencil-square color=#c8793c >}} Task\n\nComplete the following arguments to construct the observational model and the fit the model using the `bru` function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlik = bru_obs(formula = ...,\n    family = ...,\n    data = ...,\n    ips  = ...)\nfit = bru(..., ...)\n```\n:::\n\n\n\n::: {.cell webex.hide='Click here to see the solution'}\n\n<div class='webex-solution'><button>Click here to see the solution</button>\n\n```{.r .cell-code  code-fold=\"show\"}\nlik = bru_obs(formula = eta,\n    family = \"cp\",\n    data = mrsea$points,\n    ips  = ips)\nfit = bru(cmp, lik)\n```\n\n\n</div>\n:::\n\n:::\n\nOnce the model is fitted we can predict and plot the intensity for all seasons:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nppxl <- fm_pixels(mrsea$mesh, mask = mrsea$boundary, format = \"sf\")\nppxl_all <- fm_cprod(ppxl, data.frame(season = seq_len(4)))\n\nlambda1 <- predict(\n  fit,\n  ppxl_all,\n  ~ data.frame(season = season, lambda = exp(space_time + Intercept))\n)\n\npl1 <- ggplot() +\n  gg(lambda1, geom = \"tile\", aes(fill = q0.5)) +\n  gg(mrsea$points, size = 0.3) +\n  facet_wrap(~season) +\n  coord_sf()\npl1\n```\n\n::: {.cell-output-display}\n![](practical1_compiler_files/figure-pdf/unnamed-chunk-80-1.pdf){fig-pos='H'}\n:::\n:::\n\n",
    "supporting": [
      "practical1_compiler_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{caption}\n\\usepackage{longtable}\n\\usepackage{colortbl}\n\\usepackage{array}\n\\usepackage{anyfontsize}\n\\usepackage{multirow}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}